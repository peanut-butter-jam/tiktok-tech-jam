[
  {
    "title": "Curfew login blocker with ASL and GH for Utah minors",
    "description": "To comply with the Utah Social Media Regulation Act, we are implementing a curfew-based login restriction for users under 18. The system uses ASL to detect minor accounts and routes enforcement through GH to apply only within Utah boundaries. The feature activates during restricted night hours and logs activity using EchoTrace for auditability. This allows parental control to be enacted without user-facing alerts, operating in ShadowMode during initial rollout.",
    "flag": "yes",
    "reasoning": "Yes. The feature implements geo-specific compliance for Utah minors, and multiple Utah Regulatory Obligation Units (ROUs) directly apply. The following ROUs establish explicit obligations that map to the feature's components: \nROU-163: Beginning March 1, 2024, a social media company shall prohibit a Utah minor account holder from accessing their account between 10:30 p.m. and 6:30 a.m. \nROU-164: Beginning March 1, 2024, a social media company shall restrict access to a Utah minor account holder's account between the hours of 10:30 p.m. to 6:30 a.m. Exceptions to this restriction must comply with an additional requirement of this section. The time of day is determined based on the Internet Protocol address used by the minor at the time of access. The company must provide the parent or guardian options to change or eliminate the time restriction, and set daily usage limits for the minor. A Utah minor account holder cannot bypass these access restrictions. However, a parent or guardian with account access may do so without time restrictions. \nROU-162: Beginning March 1, 2024, a social media company shall provide a parent or guardian who has given parental consent for a Utah minor account holder with a password or means to access the account, allowing viewing of all posts and messages. \nROU-160: Beginning March 1, 2024, a social media company shall not collect or use any personal information from the posts, content, messages, text, or usage activities of a Utah minor account holder, except for information necessary to comply with state or federal law. \nROU-154: Beginning March 1, 2024, a social media company may not permit a Utah resident who is a minor to be an account holder on the social media company's social media platform unless the Utah resident has the express consent of a parent or guardian. This applies to any social media platforms targeting Utah residents. \nROU-161: Beginning March 1, 2024, a social media company shall prohibit the use of targeted or suggested groups, services, products, posts, accounts, or users in the account held by a Utah minor. \nROU-157: Beginning March 1, 2024, a social media company shall prohibit direct messaging between a Utah minor account holder and any other user not linked to the account through friending. \nROU-159: Beginning March 1, 2024, a social media company shall prohibit the display of any advertising in the account held by a Utah minor.",
    "recommended_actions": [
      "Implement geolocation-based gating to enforce the Utah-curfew (10:30 p.m. to 6:30 a.m.) for minor accounts, using IP-based location checks as required by ROU-164.",
      "Apply ASL (age-sensitive logic) to classify accounts as minors and enforce the curfew and related restrictions (per ROU-163/ROU-164).",
      "Route enforcement through the Geo-handler (GH) to ensure enforcement only within Utah boundaries, aligning with ROU-164.",
      "Implement parental controls to allow consented parents/guardians to access or supervise minor accounts (ROU-162); design appropriate access workflows while maintaining auditing boundaries.",
      "Limit data collection and usage for minor accounts to comply with privacy constraints (ROU-160); ensure EchoTrace logs contain only compliance-relevant, non-content data.",
      "Honor Utah-minor prohibitions on advertising, targeting, direct messaging, and content restrictions (ROU-159, ROu-161, ROu-157) during curfew enforcement.",
      "Roll out in ShadowMode initially, gathering analytics without user impact, then proceed to a full rollout with user-facing alerts as appropriate after validation against ROUs.",
      "If the regulation/documentation is not present in the KB, upload the Utah regulation document to Regulation Page (pdf) for traceability, though ROUs already provide regulatory grounding."
    ]
  },
  {
    "title": "PF default toggle with NR enforcement for California teens",
    "description": "As part of compliance with California’s SB976, the app will disable PF by default for users under 18 located in California. This default setting is considered NR to override, unless explicit parental opt-in is provided. Geo-detection is handled via GH, and rollout is monitored with FR logs. The design ensures minimal disruption while meeting the strict personalization requirements imposed by the law.",
    "flag": "yes",
    "reasoning": "Geo-specific requirement identified: the feature targets California residents under 18, aligning with SB976, requiring CA-focused age assurance and parental-consent workflows. Supporting ROUs: ROU-123: Annual disclosure of minor user statistics and parental consent for addictive feeds. ROU-124: Regulation adoption and public comment on age assurance and parental consent by January 1, 2027. ROU-125: Authorization for Attorney General to adopt exceptions aimed at protecting minors. These ROUs imply the system must track minor user counts, verifiable parental consent, enforce default PF disablement for CA minors unless consent is provided, and remain adaptable to regulatory changes; implement geo-detection via GH, leverage FR for rollout monitoring, and prepare for CA-specific regulatory updates.",
    "recommended_actions": [
      "Implement CA geo-detection (GH) to identify users located in California and under 18 for gating enforcement.",
      "Default PF (Personalized feed) should be disabled for CA minors under 18; require verifiable parental consent to enable PF.",
      "Develop a robust parental-consent workflow with verification, linkage to user accounts, and auditable consent logs; allow override only where permitted by regulation.",
      "Build age-assurance capabilities and prepare for regulatory updates per ROU-124 (adoption of age assurance regulations by 2027) and to accommodate potential exceptions per ROU-125.",
      "Implement reporting capabilities to satisfy ROU-123 (annual disclosure of minor user statistics, parental consent, and access controls) including dashboards and exportable data.",
      "Ensure FR-based rollout monitoring and observability around consent events, disablement of PF, and re-enablement upon consent changes.",
      "Design the feature to be adaptable to future regulatory changes and carve-outs (per ROU-125) and keep the regulation document on Regulation Page up-to-date for any new ROUs or amendments.",
      "Coordinate with the regulation ingestion team to fetch updated CA ROUs if SB976 text or related regulations evolve"
    ]
  },
  {
    "title": "Child abuse content scanner using T5 and CDS triggers",
    "description": "In line with the US federal law requiring providers to report child sexual abuse content to NCMEC, this feature scans uploads and flags suspected materials tagged as T5. Once flagged, the CDS auto-generates reports and routes them via secure channel APIs. The logic runs in real-time, supports human validation, and logs detection metadata for internal audits. Regional thresholds are governed by LCP parameters in the backend.",
    "flag": "yes",
    "reasoning": "ROU-170: Providers must report to CyberTipline/NCMEC any facts or circumstances indicating an apparent or imminent violation of federal laws relating to child pornography, as soon as reasonably possible after obtaining actual knowledge. The report must include the provider's contact information and may include identifying details and geographic location (e.g., IP addresses). This directly supports real-time CSAM reporting triggered by T5 detection. ROU-171: NCMEC must forward each report to federal/state/local law enforcement agencies involved in the investigation, and may involve designated foreign law enforcement. This implies downstream data sharing in the geo-specific flow. ROU-177: NCMEC is permitted to disclose report information to designated Federal, state, local, or tribal law enforcement agencies (and certain foreign agencies). This reinforces cross-agency data disclosures. ROU-178: Providers must preserve report contents and related materials for 1 year in a secure location with controlled access, aligned with CSF guidance. This drives retention and secure storage requirements for detection and reporting artifacts. ROU-187/ROU-189: EU Regulation 2021/1232 introduces geo-specific data processing obligations to combat online child abuse; if serving EU regions, the feature must adapt to EU requirements. Additionally, US state-level ROUs (e.g., ROU-130, ROU-149) highlight liability and age-verification considerations, reinforcing the need for region-aware controls. Together, these ROUs establish that the feature cannot be US-agnostic and must implement geo-specific reporting, data handling, retention, and cross-border disclosure logic. If the regulation document for CyberTipline/NCMEC reporting is missing in the system, regulation upload will be required to refine data fields and workflow.",
    "recommended_actions": [
      "Implement US CyberTipline/NCMEC reporting workflow triggered by T5 detections, including required metadata (provider contact info, geographic indicators such as IP-derived location, timestamps, and content identifiers) and real-time or near-real-time submission to the CyberTipline.",
      "Enable automated routing from CDS to NCMEC and onward to appropriate law enforcement per ROU-171/ROU-177, with configurable human-in-the-loop validation as needed.",
      "Enforce 1-year secure retention of all report contents and related materials in a controlled, auditable storage system aligned with CSF guidance (ROU-178).",
      "Introduce LCP-based regional gating to tailor reporting behavior by jurisdiction (US vs EU vs others) and ensure data handling aligns with local compliance obligations (ROU-187/ROU-189 for EU, US state-level considerations as applicable).",
      "Extend the data model to include mandatory US reporting fields and ensure secure transmission channels (encryption in transit and at rest) and strict access controls.",
      "Prepare for cross-border disclosures to foreign law enforcement where applicable, documenting authorization and audit trails (ROU-171, ROU-177).",
      "If deploying in the EU or serving EU users, implement Regulation (EU) 2021/1232 processing requirements, data minimization, and transparency as applicable (ROU-187/ROU-189).",
      "Regulate updates to policy and data flows based on the Regulation document governing CyberTipline/NCMEC reporting. If regulation is missing in the system, upload the regulation pdf via Regulation Page as guided."
    ]
  },
  {
    "title": "Content visibility lock with NSP for EU DSA",
    "description": "To meet the transparency expectations of the EU Digital Services Act, we are introducing a visibility lock for flagged user-generated content labeled under NSP. When such content is detected, a soft Softblock is applied and GH ensures enforcement is restricted to the EU region only. EchoTrace supports traceability, and Redline status can be triggered for legal review. This feature enhances accountability and complies with Article 16’s removal mechanisms.",
    "flag": "yes",
    "reasoning": "The feature requires geo-specific compliance logic because it enforces EU-region only visibility and enforcement of NSP-labeled content in line with the EU Digital Services Act (DSA) removal mechanisms (e.g., Article 16). Implementing a EU-only visibility lock and EU-region enforcement necessitates region-detection, targeted removal actions within the EU, and alignment with EU notice-and-action processes. The following ROUs in the system support and constrain this geo-specific approach:\n- ROU-196: Providers of hosting services must ensure that any action taken in response to a notice is strictly targeted, aimed at removing or disabling access to specific items constituting illegal content, while preserving the freedom of expression.\n  - Implication: Actions (like visibility locks) should target only the NSP content item within the EU jurisdiction, not globally.\n- ROU-195: Providers of hosting services must implement easily accessible notice and action mechanisms that allow individuals or entities to notify them of illegal content, ensuring these mechanisms are easy to find and use.\n  - Implication: The EU geo-flow should be supported by clear, user-facing notice processes within the EU to satisfy EU expectations and potential DPS interactions.\n- ROU-181: Member States shall implement national laws imposing diligence requirements on providers of intermediary services related to handling illegal content and online disinformation to ensure alignment with this Regulation. Such laws must be harmonized across the internal market.\n  - Implication: Supports a harmonized, EU-wide approach to geo-specific enforcement rather than regional divergence.\n- ROU-184: Member States are prohibited from establishing or maintaining additional national requirements that conflict with the rules of this Regulation without explicit provision within the Regulation itself.\n  - Implication: Encourages uniform EU-wide application for geo-restrictions and removal actions.\n- ROU-187: Regulation (EU) 2021/1232 requires providers of number-independent interpersonal communications services to employ technologies for processing personal and other data specifically for combating online child sexual abuse.\n  - Implication: Supports data processing and enforcement capabilities in the EU context when handling NSP content and related traces.\n- ROU-200: Recipients of the service and any body, organisation or association mandated to exercise rights under this Regulation may lodge a complaint against providers of intermediary services alleging an infringement of this Regulation with the Digital Services Coordinator in the territory where the recipient is located or established.\n  - Implication: Establishes EU-specific oversight and escalation channels for geo-located enforcement actions.\nWhat this means for the feature:\n- Implement EU-region detection and ensure visibility locks, soft blocks, and enforcement are applied only within the EU jurisdiction for NSP content.\n- Route removal and visibility actions through EU notice-and-action workflows and ensure narrowly targeted actions per item (not broad global suppression).\n- Ensure EchoTrace traceability and data handling adhere to EU requirements, and provide EU-specific complaints/review flows where applicable.\n- Align with harmonized EU standards and ensure no conflicting national requirements.\n\nCited ROUs:\n- ROU-196: Providers of hosting services must ensure that any action taken in response to a notice is strictly targeted, removal or disabling access to specific items constituting illegal content, while preserving the freedom of expression.\n- ROU-195: Providers of hosting services must implement easily accessible notice and action mechanisms that allow individuals or entities to notify them of illegal content, ensuring these mechanisms are easy to find and use.\n- ROU-181: Member States shall implement national laws imposing diligence requirements on providers of intermediary services related to handling illegal content and online disinformation to ensure alignment with this Regulation. Such laws must be harmonized across the internal market to promote cross-border service provision and protect rights as stated in Article 26 of the TFEU.\n- ROU-184: Member States are prohibited from establishing or maintaining additional national requirements that conflict with the rules of this Regulation without explicit provision within the Regulation itself. This ensures a uniform application of these rules across the internal market for intermediary services.\n- ROU-187: Regulation (EU) 2021/1232 requires providers of number-independent interpersonal communications services to employ technologies for processing personal and other data specifically for combating online child sexual abuse.\n- ROU-200: Recipients of the service and any body, organisation or association mandated to exercise the rights conferred by this Regulation on their behalf shall have the right to lodge a complaint against providers of intermediary services alleging an infringement of this Regulation with the Digital Services Coordinator in the territory where the recipient of the service is located or established.",
    "recommended_actions": [
      "Implement EU-region geofencing so NSP content visibility locks apply only within the EU.",
      "Route all NSP-related removal actions through EU notice-and-action workflows and ensure actions are narrowly targeted to the specific NSP item.",
      "Ensure EchoTrace logging and data handling comply with EU data protection and regulatory requirements; enable EU-specific review and escalation paths.",
      "Integrate EU-facing notice mechanisms and Digital Services Coordinator escalation channels as per EU requirements.",
      "Harmonize the feature with EU-wide rules to avoid conflicting national requirements and document alignment with ROU-181 and ROU-184."
    ]
  },
  {
    "title": "Jellybean-based parental notifications for Florida regulation",
    "description": "To support Florida's Online Protections for Minors law, this feature extends the Jellybean parental control framework. Notifications are dispatched to verified parent accounts when a minor attempts to access restricted features. Using IMT, the system checks behavioral anomalies against BB models. If violations are detected, restrictions are applied in ShadowMode with full audit logging through CDS. Glow flags ensure compliance visibility during rollout phases.",
    "flag": "yes",
    "reasoning": "The feature targets Florida-specific minor protection rules and requires geo-specific compliance logic. Florida ROUs explicitly govern parental consent, minor account restrictions, liability for failing to prevent access to harmful material, and enforcement jurisdiction, which are directly relevant to Jellybean's parental notification and access-control flows. Cited Florida ROUs informing this evaluation:\n- ROU-132: Social media platforms must prohibit minors from creating new accounts and provide verification methods to prevent minor access (applies when the user is in Florida).\n- ROU-139: Minors aged 14 or 15 require parental consent to create an account.\n- ROU-143: Jurisdictional obligations for social media platforms regarding minor account holders, including enforcement considerations under Florida law.\n- ROU-149: Commercial entities that fail to prohibit access to material harmful to minors after notification are liable to the minor for such access.\n- ROU-150: Only resident minors can initiate legal action related to harmful material access; clarifies enforcement scope within Florida.\nThese ROUs map directly to the feature’s parental-consent flow, age-based gating, parental notifications, auditability, and jurisdiction-aware enforcement. The ShadowMode with full CDS audit logging aligns with liability considerations in ROU-149, while Glow flags support rollout visibility under Florida compliance.\n\nAmbiguities/edge considerations have been addressed by aligning with the explicit Florida ROUs above; if more precise statutory language is needed, regulation text should be uploaded to the Regulation Page to extract or confirm ROUs.",
    "recommended_actions": [
      "Enforce age verification to determine minor status and apply Florida ROU-139 parental-consent rules for account creation (minors 14–15 require parental consent).",
      "When a minor aged 14–15 attempts to access restricted features, trigger a verified parental-consent workflow before access is allowed, per ROU-139 and ROU-132.",
      "Implement a verified parental-notification path: notify verified parent accounts when a minor attempts restricted access, aligning with ROU-132 and ROU-149.",
      "Strengthen verification methods to prevent minor access (age gates, verified parental consent) per ROU-132.",
      "Maintain default-enabled parental controls with full audit logging; ensure ShadowMode analytics and CDS logs are available to support accountability (ROU-149).",
      "Capture and preserve logs ( parental-consent events, notification deliveries, access-block events) to support enforcement considerations (ROU-143, ROU-149, ROU-150).",
      "Document the feature-to-ROU mapping (132, 139, 143, 149, 150) for audits; consider Regulation Page uploads if the regulation text is needed for UI wording or additional ROUs.",
      "If Florida regulation text is unavailable or outdated, navigate to Regulation Page and upload the regulation document (PDF) to extract/update ROUs and ensure ongoing compliance."
    ]
  },
  {
    "title": "Unified retention control via DRT & CDS",
    "description": "Introduce a data retention feature using DRT thresholds, ensuring automatic log deletion across all regions. CDS will continuously audit retention violations, triggering EchoTrace as necessary. Spanner logic ensures all platform modules comply uniformly.",
    "flag": "yes",
    "reasoning": "This feature enforces a geo-aware data retention mechanism with per-jurisdiction thresholds (DRT) and automatic cross-region deletion, plus auditing (CDS) and cross-module consistency (Spanner). Different jurisdictions impose distinct retention and deletion obligations, so geo-specific logic is required. Supporting ROUs confirm jurisdictional retention/deletion obligations that would shape the implementation:\n\nROU-178: A provider that submits a report to the CyberTipline under subsection (a)(1) shall preserve the contents provided in the report for 1 year after submission. The provider shall also preserve any visual depictions, data, or other digital files that are reasonably accessible and may provide context or additional information about the reported material or person. Additionally, the provider must maintain the preserved materials in a secure location and limit access only to those necessary for compliance with this subsection. This preservation must comply with the most recent version of the Cybersecurity Framework developed by the National Institute of Standards and Technology, or any successor, and may be extended voluntarily for the purpose of reducing online child sexual exploitation.\nROU-138: A social media platform must permanently delete all personal information related to the terminated account of a minor, unless legal requirements state otherwise.\nROU-142: A social media platform must allow an account holder aged 14 or 15 to request termination within specified deadlines, and the confirmed parent or guardian may request termination; all personal information related to the terminated account must be permanently deleted unless legally required to maintain it.\nROU-182: The Regulation applies to intermediary service providers with targeting or significant presence in EU Member States; compliance required irrespective of establishment location.\nROU-187: Regulation 2021/1232 requires providers to employ technologies for processing data to combat online child sexual abuse.\nROU-199: Member States shall ensure that violations of the obligations laid down in this Regulation can be sanctioned effectively, proportionately, and dissuasively, taking into account the nature, gravity, recurrence, and duration of the violation, as well as the economic capacity of the infringer.\nROU-201: Member States must ensure that violations of this Regulation can be sanctioned, and penalties shall be effective, proportionate and dissuasive.\n\nAmbiguities/gaps addressed: EU retention specifics beyond anti-abuse processing are not fully enumerated in the ROUs provided here, and there is a need to map data types to the exact jurisdictional rules (e.g., which data types fall under US 1-year CyberTipline retention vs. Florida minor deletion timelines vs. EU obligations). The design should account for data tagging, event-based and time-based triggers, and legal holds across regions; backups and cross-border data flows also require explicit handling. If additional regulation text is needed, it should be uploaded to ensure complete coverage of all data types and storage layers.\n\nGeo-specific compliance logic required (summary): per-ROU retention policy registry by data type and jurisdiction; region-tagged data and retention lanes; time-based and event-based deletion triggers; cross-region auditing (CDS) and EchoTrace when violations occur; Spanner-based orchestration to ensure uniform enforcement across modules; and handling of legal holds/overrides with secure deletion verification.",
    "recommended_actions": [
      "Implement a geo-aware retention engine with a per-ROU retention policy registry (data type, jurisdiction, retention duration, deletion rule).",
      "Tag and route data into region-specific retention lanes at ingestion to enforce jurisdictional thresholds.",
      "Develop a central Data Retention Threshold (DRT) service to enforce thresholds and trigger deletions across all storage/processing modules.",
      "Integrate a CDS module to audit retention compliance and trigger EchoTrace on violations.",
      "Use Spanner-based orchestration to keep all platform modules aligned on retention state and actions.",
      "Map feature to ROUs: ROU-178, ROU-138, ROU-142, ROU-182, ROU-187, ROU-199, ROU-201",
      "Draft concrete data model and high-level implementation plan (policy schema, data-tagging strategy, lifecycle events for deletions/awareness) if needed."
    ]
  },
  {
    "title": "NSP auto-flagging",
    "description": "This feature will automatically detect and tag content that violates NSP policy. Once flagged, Softblock is applied and a Redline alert is generated if downstream sharing is attempted.",
    "flag": "yes",
    "reasoning": "The NSP auto-flagging feature requires geo-specific compliance logic due to regional regulatory obligations governing intermediary services and content moderation. The ROUs present in the system establish region-focused duties for handling illegal or harmful content, ensuring due diligence, cross-border consistency, and enforcement. Citing the relevant ROUs helps define the geo-specific controls and escalation paths necessary for compliant implementation in jurisdictions where the service operates.",
    "recommended_actions": [
      "Implement region-aware compliance layers (start with EU-focused policy) so NSP actions (flagging, Softblock, Redline escalation) align with regional requirements.",
      "EU-specific governance: implement national due-diligence workflows for intermediary services harmonized across the internal market (ROU-181) and ensure compliance when offering services in the EU (ROU-182).",
      "Harmonize behavior to avoid conflicting national rules per EU framework (ROU-184).",
      "Enable and document escalation to legal review (Redline) for unlawful content, including child sexual abuse material and non-consensual sharing (ROU-189).",
      "Account for broad dissemination obligations and direct-recipient-oriented dissemination controls (ROU-192).",
      "Address active content management in liability considerations; ensure appropriate controls, audits, and remedial capabilities (ROU-194).",
      "Prepare for sanctions and enforceable penalties alignment (ROU-199).",
      "Data handling and privacy considerations: ensure data minimization, retention, and cross-border transfer safeguards in line with GDPR when EU data is processed outside the region.",
      "Add a regional policy switch (EU-first) to apply compliant moderation workflows and reporting; plan for extensions to other regions with similar ROUs.",
      "Develop regulatory mapping, testing, and reporting capabilities to demonstrate compliance with the cited ROUs."
    ]
  },
  {
    "title": "T5 tagging for sensitive reports",
    "description": "When users report content containing high-risk information, it is tagged as T5 for internal routing. CDS then enforces escalation. The system is universal and does not rely on regional toggles or GH routes.",
    "flag": "yes",
    "reasoning": "The feature describes a universal T5 tagging and escalation flow that does not rely on regional routing, but existing ROUs show clear geo-specific obligations relevant to high-risk content handling, data processing, retention, and user rights. To be compliant across jurisdictions, the T5 tagging workflow must be paired with region-aware logic that enforces jurisdictional requirements (e.g., DPIA/algorithm analysis, CSAM data processing, retention, disclosure, and complaint-handling). The relevant ROUs indicate concrete regional controls that would interact with T5 tagging and escalation:\n- ROU-120 (California, USA): DPIA for online services involving children and protection of minors.\n- ROU-135 (Florida, USA): Requirement to analyze content-selection algorithms based on user data.\n- ROU-173 (Federal USA): Disclosures of report information by permitted channels.\n- ROU-178 (US CyberTipline context): Retention/preservation of reports and materials for a defined period with secure handling.\n- ROU-187 (EU Regulation 2021/1232): CSAM-related data processing obligations.\n- ROU-190 (EU): Distinguishing online platforms and complying with platform-specific obligations.\n- ROU-203 (EU): Internal complaint-handling systems for contested content decisions.\n- ROU-205 (EU): Algorithmic transparency/disclosure requirements for very large platforms.\n- ROU-206 (EU): Design protections and adaptations for minors.\n\"Implications\": Region-aware escalation, retention/preservation, disclosure, complaint handling, and design protections must be integrated with T5 tagging to remain compliant in each jurisdiction. Therefore geo-specific compliance logic is required even though the feature text emphasizes universality.\n",
    "recommended_actions": [
      "Implement a region-aware compliance layer in the T5 tagging workflow that applies jurisdiction-specific ROUs based on the user’s region.",
      "EU-specific actions: enforce CSAM processing protections, ensure internal complaint-handling accessibility, provide algorithmic transparency where mandated, adapt platform design for minors, and apply appropriate retention/preservation rules (ROUs 187, 190, 203, 205, 206, 178).",
      "US-specific actions: perform DPIA-like assessments for child-related risk (ROU-120), analyze content algorithms (ROU-135), and apply retention/disclosure paths where mandated (ROUs 173, 178).",
      "General governance: document region-specific T5 decision rationale, ensure auditable processes for regional compliance (DPIA, algorithm analyses, retention schedules).",
      "Data lifecycle changes: enforce region-specific retention windows (e.g., 1 year for preserved reports per ROUs related to CSAM/retention), secure storage with tight access controls, and compliant disclosure pathways.",
      "Regulation ingestion: map ROUs to current regulations; if a regulation text is missing in the system, upload the regulation PDF to the Regulation Page (Navigate to Regulation Page → Upload Regulation document (PDF)).",
      "Engineering considerations: ensure CDS escalation integrates with regional workflows, and test end-to-end region-aware routing and reporting paths across EU/US jurisdictions.",
      "ROU mappings used: ROU-120, ROU-135, ROU-173, ROU-178, ROU-187, ROU-190, ROU-203, ROU-205, ROU-206"
    ]
  },
  {
    "title": "Underage protection via Snowcap trigger",
    "description": "Snowcap is activated for all underage users platform-wide, applying ASL to segment accounts. Actions taken under this logic are routed to CDS and monitored using BB to identify deviations in usage.",
    "flag": "yes",
    "reasoning": "The feature enforces underage protection platform-wide using age-sensitive logic (ASL) and routes enforcement actions to a Compliance Detection System (CDS) with monitoring by Baseline Behavior (BB). This implicates geo-specific regulatory requirements around minors, parental consent, age assurance/verification, design protections, and mandatory disclosures. The following ROUs in the system provide solid regulatory anchors for the required geo-specific logic:\n- ROU-120: DPIA required for child-accessible design features and potential harms from design choices affecting minors.\n- ROU-123: Annual disclosure of minor user counts, verifiable parental consent, and status of access controls.\n- ROU-124: Regulations to adopt age assurance and parental consent frameworks by a specified deadline.\n- ROU-126: Parental controls (time-based limits, notification controls, privacy defaults, restricted visibility) enabled by default.\n- ROU-130: Public annual disclosure of minor user statistics and parental controls status.\n- ROU-139: In certain jurisdictions (e.g., Florida), minors (e.g., 14–15) may require parental consent to contract or create an account.\n- ROU-145: Age verification options (anonymous or standard) for access to content deemed harmful to minors, with user choice of method.\n- ROU-187: EU Regulation 2021/1232 requires technologies to combat online child sexual abuse in number-independent interpersonal communications services.\n- ROU-206: EU-wide obligation to adapt platforms to the needs of minors, including risk assessments and built-in protections.\n\nImplications for the feature include implementing age assurance/verification, parental-consent flows where required, DPIA-driven design safeguards, default-enabled parental controls, data governance for minors, and reporting requirements. EU considerations also demand protection-centric design and abuse-prevention measures for minors in communications features.\n",
    "recommended_actions": [
      "Perform a Data Protection Impact Assessment (DPIA) focusing on child design impacts and data flows (ROU-120).",
      "Implement age assurance and parental consent mechanisms in line with applicable jurisdictions (ROU-139, ROU-145; adapt to Florida or other states as needed).",
      "Enable parental controls by default (time limits, notification controls, privacy defaults, limited visibility of child metrics) and ensure CDS/BB monitoring with audit trails (ROU-126).",
      "Establish annual reporting and disclosures for minor users and parental controls status (ROU-123, ROU-130).",
      "In jurisdictions with contracting restrictions for minors, ensure account creation flows respect parental-consent requirements (ROU-139).",
      "Incorporate EU-specific protections and anti-abuse measures (ROU-187, ROU-206).",
      "Update policy docs and user-facing terms to reflect age-related design and data handling requirements.",
      "If regulation texts are missing in the system, upload them to Regulation Page to keep ROUs current."
    ]
  },
  {
    "title": "Universal PF deactivation on guest mode",
    "description": "By default, PF will be turned off for all uses browsing in guest mode.",
    "flag": "yes",
    "reasoning": "The feature affects how personalization (PF) is applied, which involves processing user data and potential profiling. EU geo-specific obligations apply when services are offered in the Union, and there is a need for uniform application across Member States, plus clear user-facing terms about data processing. Key ROUs informing this decision: \n- ROU-182: The Regulation applies to providers of intermediary services, which include services offered in the Union, with compliance required regardless of establishment location when targeting EU recipients. This creates a geographic scope trigger for guest-mode deactivation logic in an EU context. \n- ROU-184: Member States cannot impose additional national requirements that conflict with the Regulation, ensuring uniform application across the internal market. This drives a single EU-wide implementation for guest-mode behavior. \n- ROU-207: Providers must ensure that users can easily understand their terms and rights, including data processing and profiling in the service context; guest-mode changes must be transparently disclosed. \n- ROU-199/ROU-201 (sanctions context): Violations can be sanctioned effectively and proportionately, highlighting enforcement risk if profiling, consent, or disclosure practices are mishandled in the EU. \nBased on these, geo-specific (EU) compliance logic is required: ensure guest mode disables any profiling-like processing; provide transparent disclosures about personalization in both guest and non-guest modes; maintain uniform EU-wide implementation without national divergences; align consent/opt-out mechanisms and terms with EU requirements. \nCited ROUs:\nROU-182: The Regulation applies to providers of intermediary services...\nROU-184: Member States cannot impose additional national requirements that conflict...\nROU-207: Providers must ensure that users can easily understand their terms and rights...\nROU-199: Sanctions for violations must be effective, proportionate and dissuasive (and similarly in ROU-201).\n",
    "recommended_actions": [
      "Design guest-mode to guarantee no personalization/profiling occurs in EU contexts (and clearly document this in privacy notices).",
      "Update consent and privacy disclosures to reflect guest-mode behavior and any data processing in non-guest modes, ensuring EU users have clear opt-out paths for profiling.",
      "Ensure EU-wide, uniform implementation with no conflicting national rules (avoid national deviations).",
      "Implement data minimization in guest mode (e.g., avoid cookies/fingerprinting; minimize identifiers used for personalization).",
      "Update terms of service/privacy policy to document guest-mode behavior and associated data processing clearly (ROU-207).",
      "Prepare regulatory impact and compliance checklists for EU deployment; implement auditing/monitoring to ensure ongoing adherence (ROU-199/ROU-201)."
    ]
  },
  {
    "title": "Story resharing with content expiry",
    "description": "Enable users to reshare stories from others, with auto-expiry after 48 hours. This feature logs resharing attempts with EchoTrace and stores activity under BB.",
    "flag": "yes",
    "reasoning": "The feature introduces content resharing and auto-expiry, with extensive logging (EchoTrace) and integration with BB for anomaly detection. Several ROUs indicate geo-specific obligations for intermediary services and very large online platforms, especially in the EU and Utah. The EU-related ROUs require compliance for intermediary service providers and for platforms enabling information to unlimited recipients, with retention and auditability considerations. Utah-related ROUs mandate addiction-prevention and safety audits. Key ROUs:\n- ROU-182: The Regulation applies to intermediary service providers with specific targeting in EU Member States; compliance is required irrespective of establishment location if services are offered in the EU.\n- ROU-192: Providers of online platforms must ensure obligations apply to services enabling information to be made available to potentially unlimited recipients, especially when dissemination occurs upon direct recipient request.\n- ROU-202: Very large online platforms must assess systemic risks arising from design, functioning, and use, including potential misuses, with demonstrable mitigations.\n- ROU-208: Very large online platforms must submit audit reports to regulators without undue delay.\n- ROU-178: Providers must preserve CyberTipline-related materials for one year in a secure manner with restricted access.\n- ROU-165: Utah requires at least quarterly audits to detect practices that could contribute to minor addiction and remediation within 30 days.\n- ROU-153: Utah mandates addiction-prevention standards and safety measures to mitigate harms from excessive platform use.\nThe combination of regional data handling, auditability, content retention, and safety considerations means the feature requires geo-specific compliance logic to address EU data flows and retention, platform governance obligations, and Utah safety/audit requirements.",
    "recommended_actions": [
      "Design region-aware data retention and deletion policies for EchoTrace logs and 48-hour expiry to satisfy GDPR/DSA expectations and Utah safety audits.",
      "Implement EchoTrace logging that captures only essential fields (user IDs involved, content ID, timestamp, action type, region) with strong access controls and encryption.",
      "Enforce 48-hour automatic expiry with an auditable trace; provide an override mechanism for regulatory investigations or law enforcement requests.",
      "Map data flows for EU users with appropriate data transfer controls (e.g., SCCs) and region-specific processing terms.",
      "Build regulator-ready, auditable logs to support ROU-202 and ROU-208 auditing requirements.",
      "Incorporate safety controls and quarterly audit readiness for Utah (ROU-153, ROU-165), including governance around minor-addiction risk.",
      "Conduct a privacy impact assessment (PIA) for the feature and ensure regulation documents are uploaded to the Regulation Page to keep mappings current."
    ]
  },
  {
    "title": "Leaderboard system for weekly creators",
    "description": "Introduce a creator leaderboard updated weekly using internal analytics. Points and rankings are stored in FR metadata and tracked using IMT.",
    "flag": "unknown",
    "reasoning": "The Leaderboard feature uses internal analytics (FR) and an internal monitoring trigger (IMT) to rank weekly creators. This touches on analytics processing, potential personal data handling, age-related considerations, and cross-border data flows depending on the platform’s geographic scope. Without specifics on user age distribution, geographic scope, data types used to compute rankings, and data-transfer patterns, it is not possible to determine definitively whether geo-specific compliance logic is required. The following ROUs could become applicable depending on scope:\n- ROU-120: California Age-Appropriate Design Code Act — DPIA for products accessible by children.\n- ROU-124: California age assurance and parental consent regulations.\n- ROU-130: California minor user statistics and parental controls disclosure.\n- ROU-135: Florida algorithm analysis for content selection.\n- ROU-152: Florida anonymous age verification.\n- ROU-178: CyberTipline preservation requirements.\n- ROU-181: EU member-state diligence for intermediary services handling illegal content.\n- ROU-187: EU Regulation 2021/1232 on combating online child abuse.\nThese ROUs would be triggered by factors such as whether minors are in scope, cross-border data transfers, data retention, and the regulatory treatment of ranking/algorithmic features. Given the lack of information on user age, geographic scope, data types used for ranking, and data-flow, a precise geo-specific conclusion cannot be drawn at this time.\n\nCited ROUs (illustrative, context-dependent):\nROU-120: California Age-Appropriate Design Code Act — DPIA for child-accessible products.\nROU-124: California age assurance and parental consent regulations.\nROU-130: California minor user statistics and parental controls disclosure.\nROU-135: Florida algorithm analysis for content selection.\nROU-152: Florida anonymous age verification.\nROU-178: CyberTipline preservation requirements.\nROU-181: EU member-state diligence for intermediary services handling illegal content.\nROU-187: EU Regulation 2021/1232 for combating online child abuse.\nIf regulation is the missing piece, uploading the regulation documents will enable precise mapping to ROUs and a definitive yes/no decision.",
    "recommended_actions": [
      "Gather information on regulatory scope before concluding (see Missing Information).",
      "If regulation is missing, navigate to Regulation Page and upload the relevant PDFs for the target jurisdictions to enable precise ROU mapping."
    ]
  },
  {
    "title": "Mood-based PF enhancements",
    "description": "Adjust PF recommendations based on inferred mood signals from emoji usage. This logic is soft-tuned using BB and undergoes quiet testing in ShadowMode.",
    "flag": "yes",
    "reasoning": "Mood-based inference for content personalization qualifies as profiling and automated decision-making around the user PF. This has geo-specific implications, including DPIA obligations, algorithmic transparency, and safeguards for minors and addiction risks. Relevant ROUs indicate that when mood/inferred emotional state is used to adjust feed, you must assess design impacts, disclose and explain algorithms, obtain or respect user consent where required, and implement safeguards. The following ROUs support the need for geo-specific controls and disclosures:\n- ROU-120: DPIA requirement for features accessible to children and for design choices that could increase usage or be detrimental to a child’s health.\n- ROU-135: obligation to analyze and introspect content-selection algorithms that rely on user data.\n- ROU-205: obligation to inform users about the use of algorithmic systems and, where applicable, disclose essential parameters or modification options.\n- ROU-153 / ROU-166 / ROU-168 / ROU-169: Utah-specific protections addressing addiction risk, safety standards, and non-addictive design expectations for large platforms, including minors.\n- ROU-160: strict limitations on collecting or using personal information from Utah minor accounts, with narrowing exceptions for compliance purposes.\n- ROU-187 / ROU-197 / ROU-205: EU provisions on defense against online harms, transparency of algorithmic processing, and notices regarding algorithmic systems.\nThese ROUs imply that implementing mood-based PF enhancements will require (a) DPIA; (b) transparent user-facing disclosures about how mood inferences influence PF; (c) opt-in/opt-out or configurability where required; (d) age-based safeguards and data minimization for minors; (e) safeguards to mitigate potential addiction or harm; and (f) clear regulatory documentation within the system if regulations are not yet present locally. ShadowMode should be strictly non-impactful to PF and used only for analytics.",
    "recommended_actions": [
      "Perform a Data Protection Impact Assessment (DPIA) before full rollout, especially if mood-based PF could affect children or user well-being (ROU-120).",
      "Implement transparent notices and consent mechanisms for mood-based PF and automated feed decisions; provide opt-out or user-adjustable personalization controls where feasible (ROU-135, RO U-205).",
      "Disclose algorithmic processing related to mood inferences and provide access to essential parameters or modification options where required (ROU-205).",
      "Enforce age-based safeguards and minimize data collection for minors; restrict mood data collection/use for Utah minor accounts unless strictly compliant (ROU-160, ROU-153).",
      "Incorporate safeguards to mitigate addictive usage patterns (e.g., usage reminders, time-outs) as per Utah requirements and general safety expectations (ROU-153, RO U-166, RO U-168, RO U-169).",
      "Ensure data governance: data minimization, secure processing, potential pseudonymization, and comply with cross-border data considerations as indicated by EU/Utah regulations (ROU-187, ROU-197, RO U-205).",
      "Use ShadowMode for analytics only and ensure mood-inference does not influence PF behavior in ShadowMode; obtain necessary disclosures before any production rollout.",
      "If regulatory texts are missing in the system, upload the relevant regulations to Regulation Page (PDF) to enable precise DPIA and implementation mapping."
    ]
  },
  {
    "title": "New user rewards via NR profile suggestions",
    "description": "At onboarding, users will receive NR-curated profiles to follow for faster network building. A/B testing will use Spanner.",
    "flag": "yes",
    "reasoning": "The feature involves onboarding users and delivering NR-curated profiles based on user data (profiling/recommendation). This triggers geo-specific regulatory considerations around data collection, profiling, minors’ rights, and cross-border data handling. ROUs in the system indicate location- and age-based restrictions, algorithm transparency, and data handling requirements that could apply depending on user jurisdiction and whether minors are involved. Key implications include consent, age verification, parental controls, algorithm analysis, and data retention/sharing rules. Relevant ROUs inform region-specific obligations and governance for onboarding and profiling:\n- ROU-130: An operator shall publicly disclose, on an annual basis, the number of minor users of its addictive internet-based service and how many have verifiable parental consent, along with the status of parental controls as per Section 27002.\n- ROU-132: Social media platforms are required to prohibit minors from creating new accounts... (Florida-based minor account prohibitions and verification requirements).\n- ROU-135: A social media platform must analyze algorithms employed to select content for users based on user data (algorithm transparency requirements in Florida).\n- ROU-152: Third parties conducting anonymous age verification must not retain personal identifying information after verification and must keep it anonymous.\n- ROU-160: Utah minor data restrictions; shall not collect or use PI from a Utah minor’s account beyond what is necessary for compliance.\n- ROU-161: Utah minor accounts must not be targeted or shown suggested groups/services.\n- ROU-164: Utah minor accounts have time restrictions and parental controls (guardian can adjust).\n- ROU-176: Federal US standard that providers are not required to monitor all user content.\n- ROU-182: EU intermediary service obligations apply to providers with EU relevance.\n- ROU-187: EU Regulation 2021/1232 requires processing to combat online child sexual abuse.\nThese ROUs imply region-aware onboarding prompts, age-appropriate data collection, parental controls, algorithm transparency, data retention limits, and EU compliance considerations for the NR profile suggestions feature.",
    "recommended_actions": [
      "Implement region-aware onboarding flows with location-based consent prompts for data collection and profiling; gate NR profile suggestions by age and require age verification where legally necessary.",
      "Enforce parental controls and minor protections (e.g., Florida/Utah-like protections): implement parental consent workflows, provide account termination options, and avoid targeting minors (ROU-132, ROU-161, ROU-164).",
      "Provide algorithm transparency and governance: log factors used for NR profile suggestions and establish audit/disclosure mechanisms in jurisdictions requiring visibility into data processing (ROU-135).",
      "Ensure data handling and retention practices align with age-verification requirements: no retention of PI post-verification and data minimization (ROU-152).",
      "Prepare EU-readiness: comply with EU intermediary-service obligations (ROU-182) and CSA-abuse safeguards if applicable (ROU-187).",
      "Assess cross-border data transfer considerations and data localization needs per applicable ROUs.",
      "Update the compliance program to map onboarding data flows to regional privacy laws and prepare jurisdiction-specific disclosures for minors.",
      "Regulation ingestion; if regulation documents are missing, upload regulation PDFs to Regulation Page (navigate Regulation Page -> Upload regulation PDF)."
    ]
  },
  {
    "title": "Creator fund payout tracking in CDS",
    "description": "Monetization events will be tracked through CDS to detect anomalies in creator payouts. DRT rules apply for log trimming.",
    "flag": "unknown",
    "reasoning": "The feature involves payout tracking and log retention in the Compliance Detection System (CDS) with Data Retention Threshold (DRT) rules, but there is insufficient evidence in the currently stored Regulatory Obligation Units (ROUs) to determine whether geo-specific compliance logic is required. The ROUs retrieved are largely EU Digital Services Act-related and a US reporting penalty, none of which directly address payout data processing, creator personal data, AML/KYC for payouts, or retention specifics for financial/log data. Key unknowns preventing a clear determination include: (1) which jurisdictions apply to the CDS usage for payout Tracking (EU, UK, US, others); (2) whether payout processing involves creators’ personal data and which data protection laws apply (GDPR/UK GDPR, CCPA/CPRA, etc.); (3) the exact Data Retention Threshold (DRT) durations for payout logs and anomaly-detection logs; (4) cross-border data transfer or localization constraints for payout-related logs; (5) any AML/KYC or financial-regulation obligations tied to payout monitoring that vary by region; (6) the precise regulation texts governing payout data retention and logging in the relevant jurisdictions. Without regulation texts or ROUs that specifically cover payout privacy/retention, cross-border data transfer, or financial compliance for creator payouts, a definitive geo-specific requirement cannot be established. Related ROUs observed (contextual, not direct payout guidance): ROU-172: US reporting penalties; ROU-181/182/184/186/192/199/201: EU intermediary services, cross-border applicability, non-conflicting national rules, related directives, platform obligations, sanctions. See citations below for context: ROU-172: A provider that knowingly and willfully fails to make a report required under subsection (a)(1) shall be fined...; ROU-181: Member States shall implement national diligence requirements for providers of intermediary services to align with the internal market; ROU-182: Regulation applies to intermediary service providers with significant reach in Member States; ROU-184: Member States cannot impose conflicting additional requirements; ROU-186: Related regulations and directives remain in effect; ROU-192: Obligations apply to services enabling information dissemination upon direct request; ROU-199/201: Sanctions and penalty rules for Regulation violations.",
    "recommended_actions": [
      "If regulation texts are missing in the system, upload the relevant regulation documents (PDF) on Regulation Page, then re-run targeted ROUs searches.",
      "Perform targeted ROUs searches for: (a) GDPR/UK GDPR data processing and retention of payout-related logs; (b) AML/KYC obligations for payout monitoring (US, EU, UK, etc.); (c) cross-border data transfer and data localization requirements for financial/payout logs; (d) any region-specific data privacy or financial reporting requirements related to payout tracking.",
      "Clarify whether the CDS will process creators' personal data and where the data will be stored (data centers/regions) to determine applicable geo-specific obligations."
    ]
  },
  {
    "title": "Trial run of video replies in EU",
    "description": "Roll out video reply functionality to users in EEA only. GH will manage exposure control, and BB is used to baseline feedback.",
    "flag": "yes",
    "reasoning": "The feature targets EU/EEA users with a regional rollout of video replies, triggering geo-specific regulatory considerations for intermediary services and online safety. Relevant ROUs confirm EU-wide and member-state obligations that shape implementation:\n\n- ROU-181: Member States shall implement national laws imposing diligence requirements on providers of intermediary services related to handling illegal content and online disinformation to ensure alignment with this Regulation.\n  Implication: EU rollout must respect national diligences for intermediary services and harmonize where applicable, affecting moderation workflows and region-specific governance.\n\n- ROU-186: The existing regulations and directives that may supplement or complement this Regulation, such as those concerning audiovisual media services and related consumer protection measures through European regulatory or enforcement mechanisms, remain in effect and provide a necessary legal context for these intermediary service providers.\n  Implication: Video features in the EU/EEA must align with audiovisual media directives and consumer protections, influencing disclosures, terms, and user rights.\n\n- ROU-187: Regulation (EU) 2021/1232 requires providers of number-independent interpersonal communications services to employ technologies for processing personal and other data specifically for combating online child sexual abuse.\n  Implication: Data processing for video replies must include safety tech and safeguards to combat online child exploitation, with proper controls and workflows.\n\n- ROU-189: Member States are required to take action against unlawful content that includes the sharing of images depicting child sexual abuse and non-consensual sharing of private images as part of their enforcement of consumer protection laws.\n  Implication: Moderation and enforcement workflows must address unlawful content per EU enforcement expectations, including reporting and remediation paths.\n\nCollectively, these ROUs establish clear geo-specific compliance requirements for EU/EEA deployment, including data protection, content safety, moderation, and consumer protection considerations. Therefore, geo-specific compliance logic is required for this feature.\n\nRegulatory Obligation IDs cited:\n- ROU-181: Member States shall implement national laws imposing diligence requirements on providers of intermediary services related to handling illegal content and online disinformation to ensure alignment with this Regulation.\n- ROU-186: The existing regulations and directives that may supplement this Regulation, such as audiovisual media services and related consumer protection measures, remain in effect and provide a necessary legal context for intermediary service providers.\n- ROU-187: Regulation (EU) 2021/1232 requires providers of number-independent interpersonal communications services to employ technologies for processing personal and other data specifically for combating online child sexual abuse.\n- ROU-189: Member States are required to take action against unlawful content including child sexual abuse material and non-consensual sharing of private images as part of enforcement of consumer protection laws.",
    "recommended_actions": [
      "Implement EU-region gating (GH) for the video reply feature, ensuring rollout only in the EU/EEA.",
      "Perform GDPR-compliant data processing setup: establish a lawful basis, conduct a DPIA, apply data minimization, enforce access controls, and define retention policies.",
      "Assess data localization/transfer requirements: use EU data centers or approved cross-border transfer mechanisms (e.g., SCCs) if processing/storage occurs outside the EU.",
      "Integrate content safety and moderation aligned with ROU-187 and ROU-189: deploy automated detection for illegal content, establish escalation workflows, and provide user reporting channels.",
      "Align with audiovisual/ intermediary service obligations per ROU-186: ensure disclosures, terms, user rights, and cross-border diligence are addressed in UI/UX and policies.",
      "Document compliance artifacts: DPIA results, data processing agreements, retention schedules, and moderation logs for auditability.",
      "If regulation documents are missing in the system, request upload; otherwise proceed with the cited ROUs as the regulatory basis."
    ]
  },
  {
    "title": "Canada-first PF variant test",
    "description": "Launch a PF variant in CA as part of early experimentation. Spanner will isolate affected cohorts and Glow flags will monitor feature health.",
    "flag": "unknown",
    "reasoning": "There are no Canada-specific Regulatory Obligation Units (ROUs) available in the system to determine if geo-specific compliance is required for a Canada-first PF variant test. The ROUs surfaced via queries are US/EU-centric (e.g., California minor-user disclosures, parental-consent controls, US CyberTipline reporting, and EU diligence rules) and do not map to Canada's privacy regime (PIPEDA and provincial privacy laws) or Canada-specific data residency/cross-border transfer requirements. The Regulation document for Canada is also not present in Regulation Page, which prevents extraction of Canada-specific ROUs needed for a definitive assessment. Because the feature name explicitly targets Canada, we cannot conclude geo-specific obligations without Canada-focused ROUs or the regulation itself.\n\nPending action: If regulation is missing, upload the Canada regulation PDF to Regulation Page so ROUs can be extracted and mapping to Canada-specific obligations can be performed. The missing Canada-specific ROUs are essential to determine whether you need Canada-only gating, consent flows, disclosures, or Glow flags.\n\nSpecial note: As a next step, upload the Canada regulation (PDF) to Regulation Page and re-run Canada-focused ROU queries to obtain Canada-specific obligations to inform implementation changes.",
    "recommended_actions": [
      "Pause geo-specific gating for the Canada-first PF variant test until Canada ROUs are available.",
      "Upload the Canada regulation PDF to Regulation Page (Regulation Page > Upload PDF) to enable extraction of Canada-specific ROUs.",
      "Re-run targeted Canada-focused ROU queries after regulation is uploaded (e.g., PIPEDA, data residency, cross-border transfer, child-protection obligations).",
      "Once Canada ROUs are available, align the feature implementation with Canada-specific requirements (data residency, cross-border data handling, consent for analytics, age/parential controls) and introduce a Canada-specific Glow flag (e.g., CA-Glow) if appropriate.",
      "If applicable, add Canada-specific data handling in the feature (consent prompts for personalized feeds, disclosures, retention and cross-border transfer controls)."
    ]
  },
  {
    "title": "Chat UI overhaul",
    "description": "A new chat layout will be tested in the following regions: CA, US, BR, ID. GH will ensure location targeting and ShadowMode will collect usage metrics without user impact.",
    "flag": "unknown",
    "reasoning": "The feature targets CA, US, BR, and ID. Our current ROUs include region-specific obligations for certain US states (e.g., California and Florida) and EU-wide intermediary-service/digital-regulation obligations, but there are no BR (Brazil) LGPD data localization requirements or Indonesia (Indonesia PDPA) data residency obligations present in our ROUs. This creates an information gap for BR and ID, preventing a definitive determination of whether geo-specific compliance logic is required. Additionally, the ShadowMode analytics concept and the Geo-handler (GH) region-routing depicted in the feature description are not explicitly covered by existing ROUs, so we cannot confirm their regulatory implications without BR/ID inputs. Unknowns/gaps to resolve include: (1) BR LGPD data localization and cross-border transfer rules as they apply to chat analytics/data processing; (2) Indonesia PDPA data residency/processing requirements for analytics and cross-border transfers; (3) whether ShadowMode analytics constitutes processing of personal data under BR/ID laws and what notices/consent are required; (4) precise data elements involved in the analytics, retention periods, and data-minimization requirements; (5) how the GH routing would affect regulatory obligations across regions (e.g., data localization, access rights). Cited ROUs illustrating partial coverage (not BR/ID-specific) include: ROU-123: California minor user statistics disclosure; ROU-124: California age assurance regulations; ROU-130: California minor user disclosures and parental controls; ROU-132: Florida direct-messaging restrictions for minors; ROU-157: Utah age-restriction example; ROU-171, ROU-176: US data-sharing/monitoring posture; ROU-181, ROU-182, ROU-183, ROU-187, ROU-192, ROU-194, ROU-207: EU intermediary services/regulatory obligations. Next steps are required to resolve BR/ID gaps.",
    "recommended_actions": [
      "Upload BR LGPD regulation pdf to Regulation Page",
      "Upload Indonesia PDPA regulation pdf to Regulation Page",
      "Re-run ROUs queries after BR/ID regulations ingested to identify BR/ID-specific obligations",
      "Clarify scope and controls for ShadowMode analytics (data elements processed, consent/notice requirements, retention)",
      "Define GH (Geo-handler) implementation implications for data routing and regional compliance"
    ]
  },
  {
    "title": "Regional trial of autoplay behavior",
    "description": "Enable video autoplay only for users in US. GH filters users, while Spanner logs click-through deltas.",
    "flag": "unknown",
    "reasoning": "The feature entails region-based autoplay gating (US-only) and logging of click-through deltas. While there are ROUs addressing parental controls, addiction prevention, and general intermediary/services rules, none explicitly cover region-targeted feature gating or US-specific location-based processing for autoplay or click-through logging. The ROUs identified (126, 127, 153, 176, 181, 184, 186, 187, 189) do not map directly to a requirement for geolocation-based UX changes or consent/data-processing conditions specific to autoplay. This creates ambiguity about whether geo-specific compliance logic is mandated. To resolve, we need the actual regulation texts governing region-based feature gating, US privacy/consumer protection obligations (federal or state), and consent requirements for logging user interactions in the US context.",
    "recommended_actions": [
      "Upload the relevant US regulation documents/regulatory texts that cover autoplay, geolocation-based feature gating, and data collection/consent requirements (e.g., COPPA, CPRA/CCPA, state privacy laws) to map precise ROUs to this feature.",
      "If regulation documents are not yet available, obtain jurisdiction scope (which US federal/state laws apply), whether minors are involved, what data is logged (PII, cookies, device IDs), and whether user consent is required for region-based processing and click-through logging.",
      "Once regulation texts are present, re-run targeted ROU queries for “region-based feature gating,” “autoplay regulations,” and “geolocation privacy/logging” to determine a final yes/no decision.",
      "Consider implementing a privacy-by-design approach for US-only feature gating, including explicit user consent for location-based decisions and for logging, and ensuring parental controls are respected if minors are applicable.",
      "Prepare a plan to align feature implementation with any identified ROUs (e.g., modify gating logic, consent prompts, logging disclosures)."
    ]
  },
  {
    "title": "South Korea dark theme A/B experiment",
    "description": "A/B test dark theme accessibility for users in South Korea. Rollout is limited via GH and monitored with FR flags.",
    "flag": "unknown",
    "reasoning": "Current ROUs in the system do not include South Korea (SK) regulatory guidance related to cookies consent, analytics data processing for A/B testing, accessibility disclosures, or cross-border data transfers. The retrieved ROUs pertain to other jurisdictions (e.g., California, Florida, Utah, EU) and do not provide SK-specific obligations to anchor geo-specific compliance logic for this feature. Without SK regulations, we cannot deterministically decide whether geo-specific handling is required. The key unknowns are SK data privacy/cookies rules, consent requirements for analytics in A/B tests, data retention limitations, accessibility disclosure obligations for digital services in SK, and any SK cross-border transfer rules that could affect routing of the dark theme experiment to SK users. The missing information preventing a clear decision is the SK regulation content itself; the system guidance indicates uploading regulation documents so they can be ingested into ROUs for evaluation.",
    "recommended_actions": [
      "Upload the South Korea regulation document (PDF) to the Regulation Page so the ingestion pipeline can extract SK-specific ROUs.",
      "Re-run the evaluation once SK ROUs are ingested to determine if geo-specific compliance logic is required (e.g., SK cookie consent for analytics, data retention limits, cross-border data transfer rules, accessibility obligations).",
      "If SK ROUs indicate geo-specific requirements, implement the necessary changes to the feature (e.g., consent flows for analytics in SK, data handling in the geo-handler for SK users, and any SK-specific accessibility disclosures)."
    ]
  },
  {
    "title": "Age-specific notification controls with ASL",
    "description": "Notifications will be tailored by age using ASL, allowing us to throttle or suppress push alerts for minors. EchoTrace will log adjustments, and CDS will verify enforcement across rollout waves.",
    "flag": "yes",
    "reasoning": "The feature introduces age-based notification controls (ASL) which require geo-specific compliance logic due to jurisdictional rules around minors, parental consent, and age verification. The following ROUs indicate applicable obligations that affect how notifications to minors must be implemented and rolled out across regions: ROU-122: It is unlawful to send notifications to minors during restricted hours without verifiable parental consent. ROU-123: Annual disclosure of minor user counts, parental consent status, and access controls. ROU-124: Attorney General must adopt regulations on age assurance and parental consent. ROU-130: Annual public disclosure of minor user statistics and parental controls status. ROU-137: Florida allows a parent/guardian to request termination of a minor’s account (under 14) within 10 business days. ROU-139: Florida minors aged 14–15 require parental consent to contract for account creation. ROU-145: Florida requires age verification for access to materials harmful to minors, offering anonymous and standard verification. ROU-206: EU requires adapting platforms for minors with protection by design and risk assessments. These ROUs collectively mandate geo-aware age verification, parental consent handling, controlled notification delivery, and auditable governance, all of which influence the feature’s design and rollout.",
    "recommended_actions": [
      "Implement geo-aware age verification and parental consent workflows tied to the user’s jurisdiction (support both anonymous and standard verification as appropriate).",
      "Enforce jurisdiction-specific notification rules (throttle or suppress alerts for minors) in real-time, with audit trails for compliance adjustments.",
      "Integrate EchoTrace logging to capture adjustments to notification behavior and enable CDS-driven enforcement checks during rollout waves.",
      "Align data collection, disclosures, and controls with ROUs requiring transparency (e.g., annual minor user counts, parental consent status, and access controls).",
      "Update onboarding and account-creation flows to enforce age-related restrictions per applicable ROUs (e.g., Florida 14–15 consent rules; under-14 termination rights).",
      "Design the product with EU protections in mind (ROU-206) by embedding age-appropriate protections and risk assessments into the feature.",
      "Monitor regulatory adoption timelines (ROU-124) and implement aRegulatory Monitoring plan to adapt to new or evolving requirements.",
      "If regulatory content is missing, upload the relevant regulations to Regulation Page to ingested ROUs for continued evaluation."
    ]
  },
  {
    "title": "Chat content restrictions via LCP",
    "description": "Enforce message content constraints by injecting LCP rules on delivery. ShadowMode will initially deploy the logic for safe validation. No explicit mention of legal requirements, but privacy context is implied.",
    "flag": "yes",
    "reasoning": "The feature injects local compliance policy (LCP) rules at delivery to enforce chat content restrictions, which inherently requires geo-specific compliance logic due to jurisdictional differences in content moderation, data processing, and user safety obligations. Relevant regulatory obligations in the system indicate region-specific and harmonized requirements that must guide implementation: \n\nROU-181: Member States shall implement national laws imposing diligence requirements on providers of intermediary services related to handling illegal content and online disinformation to ensure alignment with this Regulation.\nROU-182: Regulation applies to providers of intermediary services, including hosting, irrespective of establishment location, when services are offered in the Union.\nROU-184: Member States are prohibited from establishing or maintaining additional national requirements that conflict with this Regulation; harmonization is required.\nROU-186: Existing regulations and directives supplementing this Regulation (e.g., audiovisual media directives) remain in effect and provide necessary context for intermediary providers.\nROU-187: Regulation (EU) 2021/1232 requires providers to employ technologies for processing data to combat online child sexual abuse.\nROU-188: Broadly defines illegal content to include information illegal under applicable law (hate speech, terrorist content, unlawful discriminatory content, etc.).\nROU-196: Actions in response to notices must be strictly targeted to specific illegal content, balancing safety with freedom of expression.\nROU-176: Providers are not universally required to monitor all users or communications; moderation should be targeted and rule-based rather than blanket surveillance.\nROU-153: Utah state regulation on addiction prevention and user-safety obligations for platforms.\nROU-123: California regulation requiring annual disclosures related to minors and parental consent for certain features, illustrating state-level safety considerations.\n\nTaken together, these ROUs justify a geo-aware implementation that gates LCP rule enforcement by jurisdiction, avoids universal monitoring, and supports targeted actions consistent with EU harmonization and US state variations.",
    "recommended_actions": [
      "Implement region-aware gating logic for LCP rule application by user jurisdiction (e.g., EU member states vs. US states).",
      "Design moderation actions to be targeted and rule-based rather than broad monitoring (per ROU-176).",
      "In the EU, align with ROU-181, ROU-182, ROU-184, and ROU-196 for content handling and interoperability across member states; apply child-safety data processing in line with ROU-187 and ensure content handling accounts for broader illegal-content definitions per ROU-188.",
      "In US contexts, account for state-specific obligations such as ROU-153 (Utah) and ROU-123 (California) when applicable to minors or safety disclosures.",
      "Implement data minimization and privacy safeguards for ShadowMode analytics to comply with cross-jurisdictional data protection expectations (EU and US).",
      "Establish region-specific compliance dashboards and governance processes to monitor enforcement actions, timelines, and reporting requirements as guided by the cited ROUs."
    ]
  },
  {
    "title": "Video upload limits for new users",
    "description": "Introduce limits on video uploads from new accounts. IMT will trigger thresholds based on BB patterns. These limitations are partly for platform safety but without direct legal mapping.",
    "flag": "unknown",
    "reasoning": "There is no explicit Regulatory Obligation Unit (ROU) that prescribes or forbids a video upload rate limit for new accounts. The feature mentions BB-pattern-based thresholds for internal safety, but the regulatory mapping appears unclear. There are geo-specific obligations related to onboarding, minors, and safety (e.g., parental consent, age-based access controls, addiction/safety safeguards), but none directly mandate or prohibit per-user upload throttling. Without uploaded regulations for the jurisdictions in scope, a definitive geo-specific compliance decision cannot be made. Relevant but non-prescriptive examples include: ROU-123: California minor disclosures and parental consent; ROU-126: parental control defaults; ROU-139: Florida minors’ account-creation consent; ROU-153: Utah addiction prevention and safety standards; ROU-172: penalties for required reporting; ROU-176: Federal stance on monitoring; ROU-182/186/192: EU intermediary services/DSA obligations. These illustrate that onboarding and safety considerations may have geo-specific implications, but they do not directly address video-upload rate limits for new accounts. Regulated applicability remains uncertain until jurisdiction-specific regulations (PDFs) are available in Regulation Page for exact mapping.",
    "recommended_actions": [
      "Upload regulation documents (PDF) for all jurisdictions in scope to Regulation Page so ROUs can be consulted and the final decision can be made.",
      "Once regulations are available, re-run ROUs queries to identify any explicit or implicit requirements affecting onboarding, data minimization, age verification, and safety controls that could justify or prohibit upload-rate limits.",
      "Map any applicable ROUs to the feature and prepare implementation notes if a geo-specific approach is required (e.g., age-based throttling, consent-driven controls, data minimization in onboarding).",
      "Document any internal policy considerations or risk assessments related to BB-pattern-based thresholds and platform safety in the absence of explicit regulatory guidance."
    ]
  },
  {
    "title": "Flag escalation flow for sensitive comments",
    "description": "A flow that detects high-risk comment content and routes it via CDS with Redline markers. The logic applies generally and is monitored through EchoTrace, with no mention of regional policies.",
    "flag": "yes",
    "reasoning": "The feature involves escalating sensitive comments to a compliance review process across an intermediary service, which intersects with geo-specific regulatory obligations. EU rules require region-aware handling of illegal content and online disinformation, with cross-border service considerations and formal complaint/penalty mechanisms. Relevant ROUs indicate that providers of intermediary services must implement diligent, harmonized cross-border approaches, and ensure targeted actions for illegal content while preserving rights. Specific ROUs informing geo-specific logic:\n- ROU-181: Member States shall implement national laws imposing diligence requirements on providers of intermediary services related to handling illegal content and online disinformation to ensure alignment with this Regulation. Such laws must be harmonized across the internal market to promote cross-border service provision and protect rights as stated in Article 26 of the TFEU.\n- ROU-188: The concept of 'illegal content' should broadly include information illegal under applicable law (e.g., hate speech, terrorist content, unlawful discriminatory content).\n- ROU-192: Providers of online platforms must ensure that the obligations set out in this Regulation apply to services enabling information to be made available to potentially unlimited recipients, provided dissemination occurs upon a direct request from the recipient.\n- ROU-196: Hosting providers must ensure that actions in response to a notice are strictly targeted to remove or disable access to specific items, while preserving freedom of expression.\n- ROU-199/ROU-201: Sanctions and penalties for violations must be effective, proportionate, and dissuasive; complaints can be lodged with Digital Services Coordinators in local jurisdictions.\n- ROU-200: Recipients and mandated bodies may lodge complaints with Digital Services Coordinators.\n- ROU-153: Utah-specific obligations related to addiction prevention and user content moderation, with safety standards.\nGiven the description mentions no regional policy explicitly, the presence of cross-border content and EU regulatory context requires region-aware escalation rules (EU vs non-EU) and formal hooks to regulatory notification and complaint channels as per the cited ROUs.\nCited ROUs: ROU-181: <ROU Description>, ROU-188: <ROU Description>, ROU-192: <ROU Description>, ROU-196: <ROU Description>, ROU-199: <ROU Description>, ROU-200: <ROU Description>, ROU-201: <ROU Description>, ROU-153: <ROU Description>.",
    "recommended_actions": [
      "Implement region-aware escalation routing (EU vs non-EU) with hooks to Digital Services Coordinators and complaint channels per ROU-181/ROU-200/ROU-201.",
      "Enforce targeted content actions in line with ROU-196; avoid broad removals without justification.",
      "Align EchoTrace logging to regulatory traceability requirements for audits and regulator inquiries (ROU-200/ROU-201).",
      "Explicitly define and enforce 'illegal content' per jurisdiction (ROU-188).",
      "Provide user-facing complaint mechanisms or escalation pathways where applicable (ROU-200).",
      "Account for cross-border data handling and residency considerations (ROU-181).",
      "Consider Utah-specific safety/moderation obligations if Utah user base or operations are involved (ROU-153)."
    ]
  },
  {
    "title": "User behavior scoring for policy gating",
    "description": "Behavioral scoring via Spanner will be used to gate access to certain tools. The feature tracks usage and adjusts gating based on BB divergence.",
    "flag": "yes",
    "reasoning": "The feature uses behavioral scoring to gate access to tools, which constitutes profiling/automated decision-making with geo-specific regulatory implications. EU regimes emphasize algorithmic transparency and auditing of data-driven decisions, while certain US jurisdictions (e.g., California) consider nondiscrimination in automated processing and age-related controls. Relevant ROUs supporting geo-specific compliance needs include: \nROU-135: A social media platform must analyze algorithms employed to select content for users based on user data, as per the defined criteria for a social media platform in section (e)(3). This requirement indicates the necessity for platforms to implement introspection of their data processing methods to ensure compliance with user engagement regulations.\nROU-205: Providers of very large online platforms or very large online search engines must let users know when they are using algorithmic systems by including essential parameters or informing them about modifying them.\nROU-124: The Attorney General must adopt regulations to support the provisions of this bill regarding age assurance and parental consent by January 1, 2027, and must solicit public comment regarding the impact of these regulations based on nondiscrimination characteristics as defined in existing law.",
    "recommended_actions": [
      "Implement auditability and governance for the behavioral scoring logic: document inputs, scoring rules, feature weights, decision thresholds, and an auditable trail of gating decisions.",
      "Provide user-facing disclosures about the use of behavioral scoring and allow user-initiated review or opt-out pathways where appropriate, including a potential human-in-the-loop for gating decisions with significant access impact.",
      "Log gating decisions with justifications at an operational level (not exposing sensitive model internals) to support regulatory requests and audits.",
      "Apply data minimization and strong privacy protections: limit data collection to what is necessary for gating, minimize retention, and implement pseudonymization where feasible.",
      "Jurisdiction-specific controls: enable per-region toggles for gating behavior to comply with GDPR-like transparency requirements in the EU and nondiscrimination/age-related considerations in California and other relevant jurisdictions.",
      "Develop a policy communication and consent mechanism that aligns with algorithmic transparency obligations (e.g., expose essential algorithmic parameters or choices where required by law).",
      "If your user base includes EU or California users, map the gating logic to corresponding statutory safeguards and ensure mechanisms for human review where required by law."
    ]
  },
  {
    "title": "Minor-safe chat expansion via Jellybean",
    "description": "We’re expanding chat features, but for users flagged by Jellybean, certain functions (e.g., media sharing) will be limited. BB and ASL will monitor compliance posture.",
    "flag": "yes",
    "reasoning": "The feature introduces age-based restrictions and parental controls for Jellybean-flagged users (e.g., limiting media sharing). This triggers geo-specific compliance obligations around minors, parental consent, age verification, and related data handling. The regulatory units (ROUs) present in the system indicate explicit, jurisdiction-specific requirements that would shape how this feature operates across regions. Key implications include:\n- California and other US state obligations require disclosure and age-related controls for minor users (ROU-123, ROU-130).\n- California also signals a regulatory path for age assurance and parental consent by regulatory bodies (ROU-124).\n- In Florida, age-based account creation rules exist, with prohibitions or consent requirements for minors under certain ages (ROU-133, ROU-139) and potential court-based changes (ROU-141).\n- Age verification for access to materials and the option for anonymous vs standard verification is mandated in some jurisdictions, with data-retention restrictions for verification (ROU-145, ROU-152).\n- EU requirements mandate age-/child-protection design considerations and data-processing measures to combat online child abuse (ROU-187) and general “design for minors” obligations (ROU-206).\n- These ROUs collectively imply the need for region-aware policy enforcement, consent collection, data handling/privacy safeguards, and potential regulatory disclosures (ROU-123, ROU-130). Any gaps or jurisdiction-specific text should be uploaded so exact requirements can be ingested.\n\nCited ROUs:\n- ROU-123: Operators must annually disclose the number of minor users of their addictive internet-based service or application, the number for whom verifiable parental consent to provide an addictive feed has been received, and the number of minor users regarding whom access controls are or are not enabled.\n- ROU-124: The Attorney General must adopt regulations to support the provisions of this bill regarding age assurance and parental consent by January 1, 2027, and must solicit public comment regarding the impact of these regulations based on nondiscrimination characteristics.\n- ROU-130: Operators must publicly disclose, on an annual basis, the number of minor users of its addictive internet-based service and how many have verifiable parental consent, along with the status of parental controls.\n- ROU-133: A social media platform must prohibit a minor younger than 14 from entering into a contract to become an account holder (California-specific application).\n- ROU-139: A social media platform shall prohibit any minor who is 14 or 15 years of age from entering into a contract to become an account holder without parental or guardian consent (Florida).\n- ROU-141: Court injunctions could affect enforcement of age-related account creation rules.\n- ROU-145: A commercial entity must use anonymous or standard age verification to prevent access to materials by those under 18, offering a choice between methods.\n- ROU-152: Third-party anonymous age verification must not retain PII after verification and must protect data; data-use limitations apply.\n- ROU-187: Regulation (EU) 2021/1232 requires providers to employ technologies for processing data to combat online child sexual abuse.\n- ROU-206: Providers must adapt platforms to the needs of minors, including risk assessment and built-in protections.\n\nWhat geo-specific logic is implied by these ROUs for this feature\n- Implement region-aware age verification and parental-consent flows with jurisdiction-specific thresholds (e.g., under 14, 14–15) and consent requirements.\n- Provide options for anonymous and standard age verification where required, and ensure users can choose between methods.\n- Enforce account-creation and feature-access restrictions based on age (e.g., sub-14 prohibitions without consent; 14–15 with parental consent in applicable regions).\n- Limit retention and handling of age-verification data and PII per data-protection rules; align with cross-border data transfer considerations (especially for EU regions).\n- Update privacy notices and consent flows to reflect minors’ data processing and safety protections; design features to align with minor-specific protections (EU and US state-level obligations).\n- Prepare compliance dashboards and disclosures for minor-user metrics and parental-control statuses where mandated (e.g., California ROUs).\n\nRecommended Action\n- Build region-aware age gating and consent workflows for Jellybean-flagged users, with options for anonymous and standard age verification and explicit parental-consent capture where required.\n- Enforce jurisdiction-specific account creation and feature-restriction rules (e.g., under-14 restrictions, 14–15 parental consent) and integrate with the media-sharing limitations as part of Jellybean policy.\n- Implement data-handling safeguards for age verification data (minimize retention, strong access controls, clear data-use disclosures) in line with ROUs 145 and 152; ensure cross-border data handling complies with EU requirements (ROU-187, ROU-206).\n- Design minors-focused protections and accessibility features per ROUs 206 and 187, ensuring safety-by-design in the feature expansion.\n- Prepare regulatory-disclosure readiness (minor-user statistics and parental-consent status) per ROUs 123 and 130; maintain dashboards for ongoing compliance.\n- If jurisdiction-specific regulation text is not yet uploaded, navigate to Regulation Page and upload the regulation documents (pdf) so exact requirements can be ingested and enforced.\n  Flow: Regulation Page -> Upload regulation document (pdf).\n\nRou Ids\n- 123, 124, 130, 133, 139, 141, 145, 152, 187, 206\n\nMissing Information\n- [] (no outstanding missing information detected in the current ROU set; if additional jurisdictions are involved, upload corresponding regulations to ingest new ROUs)",
    "recommended_actions": [
      "Implement region-aware age gating and consent flows for Jellybean users",
      "Provide anonymous and standard age verification options with user choice",
      "Apply jurisdiction-specific restrictions: under-14 restrictions; 14–15 requires parental consent (where applicable)",
      "Minimize retention of age-verification data and protect PII; comply with cross-border data transfer rules",
      "Adapt design and safety protections for minors per ROUs 187 and 206",
      "Prepare compliance dashboards for minor-user metrics and parental-consent status (ROU-123, ROU-130)",
      "Be ready for regulatory disclosures where mandated (ROU-123, ROU-130)",
      "Upload jurisdiction-specific regulations to Regulation Page if not already ingested"
    ]
  },
  {
    "title": "Friend suggestions with underage safeguards",
    "description": "New suggestion logic uses PF to recommend friends, but minors are excluded from adult pools using ASL and CDS logic. EchoTrace logs interactions in case future policy gates are needed.",
    "flag": "yes",
    "reasoning": "The feature introduces age-based safeguards around friend suggestions (PF) and gating minors from adult pools via Age-Sensitive Logic (ASL) and a Compliance Detection System (CDS). Geo-specific compliance logic is typically required for minors in social platforms, including consent, account creation/termination, and content governance. Cited ROUs: ROU-121: Starting January 1, 2027, operators of addictive internet-based services must not provide an addictive feed to users unless... parental consent; ROU-123: Operators must annually disclose the number of minor users and consent statuses; ROU-126: Operators must provide a mechanism for verified parents of a minor to enforce default parental controls; ROU-132: Florida minors prohibition on creating accounts and termination; ROU-133: Prohibition for minors under 14 to contract for accounts; ROU-134: Termination of accounts for under-14; ROU-135: Requirement to analyze content-selection algorithms; ROU-139: Florida minors aged 14-15 require parental consent to contract; ROU-142: Minor account termination and data deletion; ROU-143: Jurisdictional considerations for enforcement. These ROUs collectively imply geo-specific controls, age verification, parental-consent workflows, and governance of content delivery, all of which map directly to the proposed feature’s ASL/CDS gating and EchoTrace logging needs.",
    "recommended_actions": [
      "Location/jurisdiction detection: infer user jurisdiction (country, and state if USA) and apply the corresponding ROU set to gate adult-content pools for minors.",
      "Age verification and parental consent: implement verifiable age checks before placing a user into the adult-content pool; route through parental-consent flows in jurisdictions that require it (e.g., Florida 14-15).",
      "Parental controls by default: enable default ASL parental-control settings (time limits, restricted feeds, non-tailored default feed) for minor accounts.",
      "Algorithm governance: implement CDS-driven introspection of content-selection algorithms (ROU-135) to ensure compliance when selecting content for minors.",
      "Logging and traceability: implement EchoTrace-like logging of gating decisions, consent status, and policy routing events for audits.",
      "Data retention and disclosures: plan for annual disclosures of minor user counts and consent statuses (ROU-123).",
      "Shutdown/termination workflows: ensure timely termination for minor accounts and secure deletion of data when required (ROU-134/142).",
      "Compliance gating integration: ensure PF gating respects CDS policy gates and does not expose minors to adult pools.",
      "Regulatory text upload guidance (if regulation text is missing): if any required regulation text is not in the system, direct user to Regulation Page to upload PDFs."
    ]
  },
  {
    "title": "Reaction GIFs with embedded filtering",
    "description": "Enable GIFs in comments, while filtering content deemed inappropriate for minor accounts. Softblock will apply if a flagged GIF is used by ASL-flagged profiles.",
    "flag": "yes",
    "reasoning": "The feature introduces age-sensitive filtering for GIFs in comments and potential minor-targeted restrictions (Softblock for ASL-flagged profiles). Our regulatory corpus contains geo-specific obligations for Florida and Utah related to minors, account creation restrictions, parental consent, and age/verification controls. These ROUs indicate that content gating, age verification, parental consent flows, and parental access controls are required by region when minors interact with content. Cited ROUs include: ROU-132: Florida minors restrictions and content verification; ROU-133: Florida minors under 14 cannot contract to create accounts; ROU-139: Florida minors aged 14–15 require parental consent to create accounts; ROU-145: Florida age verification for access to material harmful to minors; ROU-154: Utah parental consent required for minor accounts; ROU-162: Utah parental access to minor accounts; ROU-164: Utah time restrictions on minor accounts and parental control. These ROUs collectively mandate region-aware gating, age verification, parental consent, and parental access controls for content access involving minors, which directly applies to embedded GIF filtering and ASL-flagged profiles.",
    "recommended_actions": [
      "Implement region-aware content gating for GIFs and embedding in comments based on user location (Florida, Utah, and other regulated regions).",
      "Integrate age verification workflows (anonymous or standard) to gate access to GIFs or content flagged as harmful to minors, per ROU-145.",
      "Enforce Florida-specific rules on minor account creation and consent (ROU-132, ROU-133, ROU-139) where applicable.",
      "For Utah users, implement parental consent requirements for minor accounts (ROU-154) and enable parental access controls (ROU-162).",
      "Apply Utah-aligned time-based restrictions and parental override options for minor accounts (ROU-164).",
      "Ensure GIF posting/embedding with embedded filtering triggers ASL checks and blocks for underage users unless consent/verification is met.",
      "Add comprehensive audit logging and regulatory-compliance dashboards to demonstrate adherence and support enforcement actions."
    ]
  },
  {
    "title": "Longform posts with age-based moderation",
    "description": "Longform post creation is now open to all. However, moderation for underage authors is stricter via Snowcap.",
    "flag": "yes",
    "reasoning": "The feature directly involves underage authors and age-based moderation, which triggers geo-specific compliance obligations around age assurance, parental consent, and youth-protection design requirements. Explicit ROUs in multiple jurisdictions indicate formal requirements to assess design impact on children, limit or gate account creation for minors, require parental consent, and implement robust age-verification mechanisms. To implement this feature responsibly, geo-specific logic and governance must be built in. Relevant ROUs include:\n- ROU-120: DPIA for online services accessible by children and ensuring designs do not harm children; supports design safeguards and data minimization when children may use the feature.\n- ROU-122: Prohibition on sending certain notifications to minors without parental consent, implying time/gate controls and consent checks may be required.\n- ROU-124: Regulation adoption on age assurance and parental consent; signals ongoing regulatory evolution and need for adaptable implementation.\n- ROU-132: Florida prohibits minors from creating new accounts, informing account-creation controls for underage users.\n- ROU-133: Florida requires parental consent for minors aged 14–15 to contract/hold accounts.\n- ROU-139: Florida requires parental consent for minors aged 14–15 to create an account.\n- ROU-145: Requirements for age verification to access material harmful to minors, with options for anonymous or standard verification; directly informs verifications and user flows.\n- ROU-206: EU obligation to adapt platforms for minors, including risk assessment and built-in protections in design/functionality.\nThese ROUs collectively justify geo-specific logic for age verification, parental consent workflows, tightened moderation for minors, and DPIA documentation. \n\nGeo-specific compliance logic the feature needs (high level):\n- Age verification at longform posting and author creation with verifiable options (anonymous or standard) and minimum data collection (ROU-145; ROU-120).\n- Parental/guardian consent workflows for under-18 users where required by jurisdiction (ROU-132; ROU-133; ROU-139; ROU-124).\n- Stricter Snowcap moderation for underage authors, with escalation and auditing to align with child-protection design requirements (ROU-120; ROU-206).\n- Content access and moderation controls for minors in jurisdictions with content restrictions (ROU-145; ROUs around Florida protections).\n- DPIA and ongoing risk assessment for design features affecting children, including cross-jurisdictional considerations (ROU-120; ROU-206).\n- Jurisdiction-specific enforcement and reporting pathways (e.g., Florida and EU-related obligations) to address potential liabilities and regulatory actions (ROU-132, ROU-133, ROU-139, ROU-145; ROU-206).\n\nIf regulation texts are missing for a target region, regulation intake should be used to fetch/ingest the exact obligations so that the implementation can be aligned precisely (see Regulation intake process in the system).",
    "recommended_actions": [
      "Implement geo-aware age gating: require age verification before enabling longform posting for users below defined thresholds; support both anonymous and standard verification methods (ROU-145).",
      "Design and implement robust parental consent flows where required (ROU-132, ROU-133, ROU-139; ROU-124), including consent capture, verification, and audit trails.",
      "Integrate Snowcap-based moderation for underage authors with escalation paths, stricter review, and design protections (ROU-120; ROU-206).",
      "Conduct a Data Protection Impact Assessment (DPIA) for the child-facing design and posting flow to evaluate risks and mitigation strategies (ROU-120).",
      "Align EU-specific protections by incorporating risk-based design adaptations and child protections (ROU-206).",
      "Apply Florida-specific controls for account creation and consent where applicable (ROU-132, ROU-133, ROU-139).",
      "Maintain data minimization and privacy-by-design practices in age-verification and consent flows (ROU-120).",
      "Monitor regulatory developments (ROU-124) and update implementation as regulations evolve."
    ]
  },
  {
    "title": "Custom avatar system with identity checks",
    "description": "Users can now design custom avatars. For safety, T5 triggers block adult-themed assets from use by underage profiles. Age detection uses ASL and logs flow through GH.",
    "flag": "yes",
    "reasoning": "The feature uses age-sensitive logic (ASL) and region-based routing (GH) to govern avatar customization for minors, which triggers geo-specific regulatory considerations. The ROUs retrieved indicate explicit, jurisdiction-specific requirements around age verification, parental consent, account creation/termination for minors, content gating for minors, data-retention restrictions on age-verification data, and design-by-default protections for minors. Implementing this feature without geo-specific controls could violate region-specific laws and regulations. Relevant ROUs include: ROU-124: The Attorney General must adopt regulations to support age assurance and parental consent by January 1, 2027, with public-comment requirements. ROU-126: Operators must enable default parental controls (e.g., time limits, restricted feeds, private mode). ROU-132: Florida prohibits minors from creating accounts; ROU-133: Florida prohibits minors under 14 from entering into contracts to create accounts; ROU-134: Florida requires termination of minor accounts; ROU-139: Florida minors aged 14–15 require parental consent to contract; ROU-145: Florida requires age verification for access to material harmful to minors, offering anonymous or standard methods and allowing user choice; ROU-152: Florida requires third-party age-verification services to not retain PII after verification; ROU-155: Utah requires age verification and parental consent at account creation or within 14 days for existing users; ROU-206: EU requires providers to adapt platforms to the needs of minors and build protections into design and functionality.",
    "recommended_actions": [
      "Implement region-aware age verification and parental consent flows for avatar-related features, with support for multiple verification modalities (anonymous and standard) and explicit user choice, in line with ROU-145.",
      "Enforce default parental-control settings at onboarding and throughout the avatar feature lifecycle (e.g., time limits, restricted content, private mode) per ROU-126.",
      "Enforce jurisdiction-specific onboarding and account lifecycle rules for minors (e.g., prohibit or restrict account creation for certain ages; terminate underage accounts where required) per ROU-132, ROU-133, and ROU-134.",
      "Implement consent mechanisms for mid-teens where required (e.g., 14–15 in Florida) in accordance with ROU-139.",
      "Provide content gating for adult-themed assets to underage profiles, aligned with age-verification outcomes and Florida/Utah/EU obligations (ROU-145, ROU-155).",
      "Ensure age-verification data handling follows privacy requirements (no PII retention after verification where mandated) per ROU-152; route verification/log data through a geo-handler to respect data residency (ROU-124, ROU-206).",
      "Incorporate EU-minor protections by default into design and functionality (privacy-by-design) per ROU-206.",
      "Document and enforce data-residency and data-flow controls for age-check processes to comply with regional requirements."
    ]
  }
]